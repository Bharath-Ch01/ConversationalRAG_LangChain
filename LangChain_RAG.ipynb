{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+szoM+7+FbyI/pPZYc3QK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bharath-Ch01/ConversationalRAG_LangChain/blob/main/LangChain_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-openai langchain-core langchain_community"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v6ZsPaxfVCmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "7o0Xs8r3NuEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "id": "aqn-chhNWWRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_key=userdata.get('OPENAI_API_KEY')\n",
        "langchain=userdata.get('LANGCHAIN_API_KEY')"
      ],
      "metadata": {
        "id": "8O7-uXJlOdI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"]=openai_key"
      ],
      "metadata": {
        "id": "pmwwe4ppQ8eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-AtyVgtdOxUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"]=langchain\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"langchain_learning\""
      ],
      "metadata": {
        "id": "3uLhq96xRRLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kzjzFzcFJs9M"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "llm_response=llm.invoke(\"What is an LLM just Full form\")\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "op_parser=StrOutputParser()\n",
        "op_parser.invoke(llm_response)"
      ],
      "metadata": {
        "id": "NBILM0SKQ7GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing the same as above at at time"
      ],
      "metadata": {
        "id": "7XQ3knCKcsk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain=llm|op_parser\n",
        "chain.invoke(\"What is an LLM just full form\")"
      ],
      "metadata": {
        "id": "ZcZhtqJrcIX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pydantic model helps us define a structure instead of a simple plain text\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kju94Ybtc1vJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "#Defining the prompt\n",
        "prompt=ChatPromptTemplate.from_template(\"Give me Startup ideas related to {Sector}, Bound it to 5\")\n",
        "\n",
        "#initialize the LLM\n",
        "llm=ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "#defining the output parser\n",
        "op_parser=StrOutputParser()\n",
        "\n",
        "#compose the chain\n",
        "chain=prompt | llm | op_parser\n",
        "\n",
        "#use the chain\n",
        "result=chain.invoke({\"Sector\":\"AI\"})\n",
        "print(result)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1Nz4cD1Xc0A0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will create customized messages instead of AI message\n",
        "Ez: System message- defines the character of the system\n",
        "human message: Context of the prompt"
      ],
      "metadata": {
        "id": "egiOZ-lmp0g-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM Messages\n",
        "since llm can accept sequence of messages we can specify the chatprompttemplate, instead of regular like json or tuple type(\"name\", \"behaviour\"\n"
      ],
      "metadata": {
        "id": "rHxtFpY4qMOp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "raHRHqB6m3YQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}